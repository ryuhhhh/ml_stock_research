<プロジェクト 工程表>
# 1. データを取得
    a. 情報技術セクター(524銘柄)の米国株価より以下を取得する
       - 取得する値は1週間ずつずらし
       - 1/8より10営業日前までの値を取得
       - csvで1ヵ月ごとに取得
       - 1ヵ月ごとに取得する
       - カラムは以下に<特徴量><教師データ>に追加して以下を先頭に加える
        1. 銘柄コード+日付 の文字列
        <特徴量>
            1. 変動係数(計算)
            2. 出来高(APIで取得)
            3. 1次近似の傾き1(last 5 days)
            4. 1次近似の傾き2(last 10 days)
            5. 1次近似の傾き3(last 15 days)
            6. 1次近似の傾き4(last 20 days)
            7. 時価総額
            8. 終値(APIで取得)
        <教師データ>
            1. 次の10営業日後に直近の終値より15%以上高くなったかどうか

# 2. データを観察・整備
    a. データの全体像を見る
        - ヒストグラム
        - 散布図
    b. 性能指標を選択する
        - 分類タスクなのでcross_val_scoreやaccuracy_score
    c. テストセットを用意する(20%)
    d. 各特徴量の相関関係を見る
      - ブートストラップ法を用いてランダムに作成した相関係数をヒストグラムにしてみる
      - 外れ値の影響を受けづらい相関係数を作成することができる
    e. データを分割する
        - train_test_split()
    f. データクリーニング
        - 欠損値をimputerで中央値に変換
        or
        - 欠損値がある場合は削除
        - カテゴリ属性はone-hot-vectorに
    (☆.) 次元削減
        - 非線形ぽいのでカーネルPCA
    g. データスケーリング
        - 標準化 StandardScalerでscaler.fit_transform()
        - 最小最大スケーリング

# 3.モデルを選択し訓練する
    a. モデルを試す(最初は1ヵ月分(254×4セット)などで試しながら)
        - SGDClassifier
        - DecisionTree
        - RandomForest
        - ガウスRBFカーネルSVM
        - VotingClassifierで上記をアンサンブル
        - RandomForestでバギング
        ※ ハイパーパラメータのグリッドサーチを行う
        ※ オンラインのやり方を調査
    b.交差検証でモデルを評価する
       - (cross_val_score())
    b'.学習曲線で性能を見る
        - 誤差が大きければ過小適合。
        - モデルを複雑にする。多項式回帰の様に。
        - 訓練セットのみ小さければ過学習。
        - 過学習なら検証誤差を訓練誤差に近づけるために訓練データを増やし続ける。
        - 訓練セットと検証セットの性能を2つ同時に表示した曲線
    b'' 適合率(TP/TP+FP)が高いか確認する
    c. 保存する
    ※ モデルの訓練に時間がかかるようなら次元削減を実施するため[2.]に戻す

# 4.テストセットで検証
    a. 作成したモデルで検証セットのaccuracy_scoreを確認する


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
<StockPrice>
ポイント
・分類なら適合率(TP/TP+FP)を高くする
  - 正答を間違いだとみなしていいから，正しいものを取り上げたい
・回帰結果の重みを調べて影響力の高い変数を探す
・特徴量/インスタンスが非常に多い場合は正規方程式を使った線形回帰は時間がかかりすぎてしまう。その場合は勾配降下法を使用する。
・バイアスが高いと: モデルが間違っている可能性。過小適合しやすい。
・バリアンスが高いと: モデルの予測値の分散が高く過学習しやすい。
・バリアンスとバイアスはモデルの複雑度の高低に起因するのでトレードオフとなる。
・データの概形
    - いつから: 2020年1月~
    - 数: 米国上場株の情報技術セクター 524銘柄
    - 訓練データ: ↓のinput参照
    - 教師: 次の2週間の中で最後の高値より10%以上高いければ1
    - 1つのファイルに1カ月分を一旦まとめる
      => 1週間ずつずれて取得するので合計1ヵ月で4×524=約2096となる
        => 12カ月で 25152個のデータができる
・SVMの場合中小規模のデータセットに対し有効だがスケールの影響を受けやすい
------------------------------------
Input
・変動係数
・出来高
・傾き1(last a week)
・傾き2(last 2 weeks)
・傾き3(last 3 weeks)
・傾き4(last 4 weeks)
・時価総額
・終値

Pipeline
・値の大きいものは標準化する

Output
・次の2週間で株価は10%以上上昇するか(分類)
------------------------------------
<手順>
[First.データ準備]
データの全体像を見る
  - ヒストグラム
  - 散布図
性能指標を選択する
   -> 平均二乗誤差?
テストセットを用意する(20%ほど?)
データの相関関係を見る
   - 終値や変動係数などの相関係数
データを分割する
  - train_test_split()
データクリーニング
   - 欠損値をimputerで中央値に変換
   or
   - 欠損値がある場合は削除
   - カテゴリ属性はone-hot-vectorに
データスケーリング
    - 標準化 StandardScalerでscaler.fit_transform()
    - 最小最大スケーリング

[Second.モデル訓練]
1. モデルを選択して訓練する(最初は1ヵ月分(254×4セット)などで試しながら)
  - オンラインのやり方は?
  - 分類なら10%上がるか下がるかの二項分類(特徴量が少ないためSGDClassifierのミニバッチ勾配降下法がよい。)
  - それかガウスRBFカーネルを使用し特徴量爆発を防ぎながら予測していく
         -> ハイパーパラメータのグリッドサーチを行う
2.交差検証でモデルを評価する
  - (cross_val_score())
2'.学習曲線で性能を見る
  - 誤差が大きければ過小適合。
    - モデルを複雑にする。多項式回帰の様に。
  - 訓練セットのみ小さければ過学習。
    - 過学習なら検証誤差を訓練誤差に近づけるために訓練データを増やし続ける。
  - 訓練セットと検証セットの性能を2つ同時に表示した曲線
3. 保存する

※ モデルの訓練に時間がかかるようなら次元削減を実施するため[First]に戻す


[Third.テストセットで評価]
-> 別メモ

[Fourth]
・実際に直近の株価データで予測する

